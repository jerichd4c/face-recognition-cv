# Sistema de Reconocimiento Facial en Tiempo Real üì∑üß†

Aplicaci√≥n en Python que permite registrar personas, reconocer rostros en tiempo real y analizar emociones usando OpenCV y DeepFace, con una interfaz web simple en Streamlit y persistencia en SQLite.

- Reconocimiento facial con embeddings (Facenet, ArcFace o VGG-Face)
- An√°lisis de emociones (7 clases: angry, disgust, fear, happy, sad, surprise, neutral)
- Ajustes finos para mejorar la detecci√≥n de ‚Äúdisgust‚Äù y suavizado temporal de emociones
- Reportes interactivos (gr√°ficas, √∫ltimos eventos) y filtro por emoci√≥n
- Administraci√≥n: alta de personas y eliminaci√≥n segura (preserva historial)

---

## Requisitos previos ‚öôÔ∏è

- Python 3.10 o superior
- Windows recomendado (probado con c√°mara local). Tambi√©n funciona en otros SO con Python + OpenCV.
- C√°mara web disponible

Dependencias se instalan desde `requirements.txt`.

---

## Instalaci√≥n üì¶

En PowerShell (Windows):

```powershell
# 1) Clonar el repositorio
# git clone https://github.com/<tu-usuario>/<repo>.git
# cd <repo>

# 2) Crear y activar entorno virtual (opcional pero recomendado)
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3) Instalar dependencias
pip install -r requirements.txt
```

Notas:
- DeepFace descargar√° autom√°ticamente algunos modelos la primera vez que se ejecuta (puede tardar varios minutos).
- Si OpenCV reporta errores de DLL en Windows, instala el "Microsoft Visual C++ Redistributable".

---

## Puesta en marcha r√°pida üöÄ

Ejecuta la interfaz web:

```powershell
streamlit run app.py
```

La app abre una interfaz con tres secciones en la barra lateral:

1. Registro: alta de personas y captura de rostros (v√≠a c√°mara del navegador) para generar embeddings.
2. Detecci√≥n: lanza una ventana nativa (OpenCV) con reconocimiento en tiempo real y an√°lisis de emociones.
3. Reportes: estad√≠sticas, gr√°ficas por emoci√≥n y √∫ltimos eventos (con filtro por emoci√≥n).

Para cerrar la ventana nativa de detecci√≥n, presiona la tecla `q`.

---

## Flujo de trabajo üß≠

### 1) Registrar personas
- Completa Nombre, Apellido y Email.
- Usa la c√°mara para tomar varias capturas (se recomienda ‚â• 5, con buena iluminaci√≥n y rostro centrado).
- El sistema detecta y recorta el rostro m√°s grande de cada captura y guarda el embedding en la tabla `Rostro`.

Administraci√≥n:
- Puedes eliminar una persona desde la misma p√°gina. La eliminaci√≥n borra sus embeddings y deja en `NULL` el `id_persona` de detecciones hist√≥ricas, preservando el historial.

### 2) Detecci√≥n en tiempo real
- Configura los par√°metros (umbral de reconocimiento, intervalos, backends, modelos, resoluci√≥n, FPS, etc.).
- Pulsa ‚ÄúIniciar‚Äù para abrir la ventana nativa. Se ver√°n:
  - Caja del rostro, nombre si hay match y confianza de reconocimiento
  - Emoci√≥n dominante y confianza
  - Top-3 emociones (ayuda para calibraci√≥n)
  - FPS actual
- Pulsa ‚ÄúDetener‚Äù o cierra con `q`.

Calibraciones de emoci√≥n importantes:
- Ganancia de ‚Äúdisgust‚Äù (por defecto 1.6) para mejorar su sensibilidad.
- Suavizado temporal (ventana en frames) para reducir parpadeo.
- Balanceo por prior (opcional) para evitar que una emoci√≥n quede subrepresentada.

### 3) Reportes
- M√©tricas generales (personas registradas, detecciones del d√≠a, emoci√≥n predominante, tasa de reconocimientos confiables).
- Gr√°fica de distribuci√≥n de emociones por persona.
- √öltimas detecciones (aplica filtro por emoci√≥n si eliges una).

---

## Uso por l√≠nea de comandos (opcional) üñ•Ô∏è

Adem√°s de la UI, puedes usar el script nativo `camera_local.py`.

### Registrar desde CLI

```powershell
python camera_local.py register --camera 0 --nombre "Juan" --apellido "P√©rez" --email "juan@example.com"
```

Opciones √∫tiles:
- `--person-id <id>`: agrega capturas a una persona existente.
- `--duplicate-threshold 0.8`: umbral de similitud para advertir duplicados.
- `--force`: guarda aunque parezca duplicado.

Presiona `c` para capturar y `q` para salir (m√≠nimo recomendado: 5 capturas).

### Detectar desde CLI

```powershell
python camera_local.py detect --camera 0 --threshold 0.6 --infer-interval-ms 500
```

Par√°metros importantes (resumen):
- Reconocimiento:
  - `--threshold`: similitud coseno m√≠nima para considerar un match.
  - `--embed-model`: `ArcFace`, `Facenet` (default), `VGG-Face`.
  - `--detector-backend`: `opencv`, `opencv-dnn`, `retinaface`, `mediapipe`.
- Emociones:
  - `--no-emotion`: deshabilita emociones para m√°ximo FPS.
  - `--emotion-backend`: `opencv`, `retinaface`, `mediapipe`, `skip`.
  - `--emotion-interval-ms`: cada cu√°nto recalcular emociones.
  - `--emotion-scale`: upscale del recorte de emociones (mejor detalle).
  - `--crop-padding`: padding alrededor del rostro para emociones.
  - `--emo-disgust-gain`: ganancia a ‚Äúdisgust‚Äù (default 1.6).
  - `--emo-smooth-frames`: suavizado temporal (frames).
  - `--emo-balance`, `--emo-balance-strength`, `--emo-balance-alpha`.
- Rendimiento:
  - `--frame-width`, `--frame-height`: resoluci√≥n de la c√°mara.
  - `--detect-scale` y `--scale`: aceleran detecci√≥n / embeddings.
  - `--force-mjpg`: reduce carga CPU en algunos drivers.
  - `--target-fps`: intenta fijar FPS.
  - `--box-smooth-alpha`: suavizado exponencial de la caja.
  - `--min-log-interval-ms`: limita frecuencia de escritura a DB.

> Tip: Para usar `opencv-dnn` necesitas colocar los archivos del modelo Caffe en `./models`:
> - `deploy.prototxt`
> - `res10_300x300_ssd_iter_140000.caffemodel`

---

## Base de datos y persistencia üóÑÔ∏è

- Archivo SQLite: `facial_recognition.db` en la ra√≠z del proyecto.
- Tablas principales:
  - `Persona(id, nombre, apellido, email, fecha_registro_timestamp)`
  - `Rostro(id, id_persona, rostro BLOB)` (embeddings)
  - `Deteccion(id, id_persona NULL, recog_confianza, emocion, emocion_confianza, timestamp)`
  - `DeteccionEmocionDetalle(id, id_deteccion, emocion, confianza)` (distribuci√≥n completa por evento)
- Migraciones b√°sicas se realizan autom√°ticamente si vienes de un esquema anterior.
- Al eliminar una persona:
  - Se borran sus embeddings en `Rostro`.
  - Se pone `id_persona = NULL` en `Deteccion` para conservar el historial.

---

## Ajustes de rendimiento y calidad ‚ö°

- Aumentar resoluci√≥n mejora la calidad de recortes, pero reduce FPS.
- `--force-mjpg` y `--target-fps` pueden reducir latencia en Windows.
- Mant√©n buena iluminaci√≥n y encuadre para mejores embeddings y emociones.
- ‚ÄúDisgust‚Äù suele infradetectarse: usa la ganancia y, si es necesario, incrementa suavizado/balanceo.

---

## Soluci√≥n de problemas üß©

- No abre la c√°mara: revisa el √≠ndice (`--camera`), permisos del SO y que otra app no la est√© usando.
- Ventana se cierra inmediatamente: mira la consola para mensajes (DLLs, permisos, drivers).
- Errores DeepFace al inicio: la primera vez descarga pesos; espera a que termine.
- Emojis/acentos extra√±os en consola: usa PowerShell con UTF-8 o evita caracteres especiales.

---

## Estructura del proyecto üìÅ

```
app.py                # Interfaz Streamlit (Registro, Detecci√≥n, Reportes)
camera_local.py       # Motor nativo (OpenCV/DeepFace) y CLI
requirements.txt      # Dependencias del proyecto
facial_recognition.db # (se crea al ejecutar) Base de datos SQLite
models/               # (opcional) Modelos Caffe para opencv-dnn
```

---

## Cr√©ditos üôå

- [OpenCV](https://opencv.org/) para video y visi√≥n por computador
- [DeepFace](https://github.com/serengil/deepface) para embeddings y emociones
- [Streamlit](https://streamlit.io/) para la interfaz web
